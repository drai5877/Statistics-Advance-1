{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xHaqIqKmQWw2",
        "outputId": "76ba4865-5f07-4276-b2f7-5bbe9d720159"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '‚Äô' (U+2019) (<ipython-input-1-3ef668fe3210>, line 20)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3ef668fe3210>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    Deals with uncountable values within a range (e.g., height, weight, time). Uses a Probability Density Function (PDF) to calculate probabilities over an interval. Example: The probability that a person‚Äôs height is between 160 cm and 170 cm.\u001b[0m\n\u001b[0m                                                                                                                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '‚Äô' (U+2019)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "STATISTICS ADVANCE 1\n",
        "\n",
        "1. What is a random variable in probability theory?\n",
        "In probability theory, a random variable is a numerical function that assigns a real number to each outcome in a sample space of a random experiment. It essentially translates uncertain outcomes into numerical values, making analysis possible.\n",
        "\n",
        "Types of Random Variables: Discrete Random Variable: Takes a countable number of possible values (e.g., number of heads in a coin toss, number of defective items in a batch). Continuous Random Variable: Takes an infinite number of values within a given range (e.g., height of students, time taken to complete a task).\n",
        "\n",
        "2. What are the types of random variables?\n",
        "Random variables are primarily classified into two types:\n",
        "\n",
        "Discrete Random Variable Takes a finite or countably infinite set of values. Commonly associated with counting (e.g., number of defective products, number of heads in a coin toss). Characterized by a probability mass function (PMF), which gives the probability of each possible value.\n",
        "Continuous Random Variable Takes an uncountable set of values, typically within an interval. Commonly associated with measurements (e.g., height, weight, time). Characterized by a probability density function (PDF), where probabilities are given by areas under a curve rather than individual values.\n",
        "3. What is the difference between discrete and continuous distribution?\n",
        "The difference between discrete and continuous distributions is:\n",
        "\n",
        "Discrete Distribution:\n",
        "Deals with countable values (e.g., number of students in a class, dice rolls). Uses a Probability Mass Function (PMF) to assign probabilities to specific values. Example: The probability of getting 3 heads in 5 coin flips.\n",
        "\n",
        "Continuous Distribution:\n",
        "Deals with uncountable values within a range (e.g., height, weight, time). Uses a Probability Density Function (PDF) to calculate probabilities over an interval. Example: The probability that a person‚Äôs height is between 160 cm and 170 cm.\n",
        "\n",
        "4. What are probability distribution functions (PDF)?\n",
        "A Probability Distribution Function (PDF) describes how probabilities are assigned to different possible values of a random variable. It defines the likelihood of each outcome occurring in a probability distribution.\n",
        "\n",
        "There are two main types of probability distribution functions:\n",
        "\n",
        "Probability Mass Function (PMF) (for discrete random variables): 1.Gives the probability of each individual value. 2.The sum of all probabilities must be 1. Example: Coin Toss: The probability of getting exactly 2 heads in 4 coin flips follows a binomial distribution PMF.\n",
        "\n",
        "Probability Density Function (PDF) (for continuous random variables):\n",
        "\n",
        "1.Represents probabilities using a continuous curve. 2.The probability of a single value is zero; instead, we calculate probabilities over intervals. 3.The area under the curve in a given interval gives the probability of the variable falling within that range. Example: Height of People: The probability that a randomly selected person is between 160 cm and 170 cm tall follows a normal distribution PDF.\n",
        "\n",
        "5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "The key difference between Cumulative Distribution Functions (CDF) and Probability Distribution Functions (PDF) is how they represent probabilities.\n",
        "\n",
        "Probability Distribution Function (PDF/PMF) Describes the likelihood of a random variable taking a specific value. For discrete variables: Uses a Probability Mass Function (PMF) that assigns probabilities to exact values. For continuous variables: Uses a Probability Density Function (PDF) where probabilities are given by areas under the curve. Example (Dice Roll - Discrete Case) Cumulative Distribution Function (CDF) Represents the cumulative probability of a random variable being less than or equal to a certain value. For discrete variables: It sums up the probabilities from the PMF. For continuous variables: It integrates the PDF from negative infinity to x. Example (Dice Roll - Discrete Case):\n",
        "6. What is a discrete uniform distribution?\n",
        "A discrete uniform distribution is a probability distribution where all possible outcomes have an equal probability of occurring. It is called \"uniform\" because the probabilities are constant across all values. Key Idea: All outcomes are equally likely. The total probability of all possible outcomes adds up to 1\n",
        "\n",
        "Example : Rolling a Fair Die\n",
        "Imagine rolling a six-sided die. The possible outcomes are 1, 2, 3, 4, 5, and 6. Since the die is fair, each number has the same chance of appearing.\n",
        "\n",
        "No number is more likely than the others. If you roll the die many times, each number appears roughly the same number of times.\n",
        "\n",
        "7. What are the key properties of a Bernoulli distribution?\n",
        "Key Properties of a Bernoulli Distribution A Bernoulli distribution is a discrete probability distribution that represents a single trial with only two possible outcomes:\n",
        "\n",
        "Success (1) with probability Failure (0) with probability 1‚àíùëù\n",
        "\n",
        "It is used to model binary outcomes, such as: Tossing a coin (Heads or Tails) Passing or Failing an exam Clicking or Not Clicking on an ad\n",
        "\n",
        "Key Properties:\n",
        "Only Two Outcomes\n",
        "The variable ùëã takes only two values: 1 (Success) and 0 (Failure).\n",
        "\n",
        "Probability Parameter ùëù\n",
        "The probability of success is denoted as p (where 0‚â§ùëù‚â§10‚â§p‚â§1). The probability of failure is 1‚àíùëù.\n",
        "\n",
        "Mean (Expected Value) ùê∏(ùëã)\n",
        "The expected value represents the long-term average outcome of many trials. It is equal to p (the probability of success).\n",
        "\n",
        "Variance Var(ùëã)Var(X)\n",
        "Measures the spread of the distribution. Given by ùëù(1‚àíùëù)\n",
        "\n",
        "Memoryless Property\n",
        "Each trial is independent of past trials. Example: If you flip a coin once, the outcome does not affect the next flip.\n",
        "\n",
        "8. What is the binomial distribution, and how is it used in probability?\n",
        "The binomial distribution is a discrete probability distribution that describes the number of successes in a fixed number of independent trials, where each trial has only two possible outcomes: success or failure.\n",
        "\n",
        "It is used when: There are n independent trials (repeated experiments). Each trial has only two possible outcomes: Success (e.g., flipping heads, passing an exam). Failure (e.g., flipping tails, failing an exam). The probability of success p, remains constant in every trial. The trials are independent, meaning the outcome of one trial does not affect another.\n",
        "\n",
        "Real-World Examples of Binomial Distribution\n",
        "Flipping a Coin: Counting how many times you get heads in 10 flips. Exam Pass Rate: Finding how many students pass an exam in a class of 50.\n",
        "\n",
        "9. What is the Poisson distribution and where is it applied?\n",
        "The Poisson distribution is a discrete probability distribution that models the number of events occurring in a fixed interval of time or space, given that the events occur independently and at a constant average rate.\n",
        "\n",
        "It is used when we want to know:\n",
        "\n",
        "How often an event happens in a given period or area. The probability of a certain number of occurrences happening within a fixed interval.\n",
        "\n",
        "Real-World Applications of Poisson Distribution\n",
        "Call Centers Estimating the number of customer calls received per hour. Example: If a call center gets an average of 10 calls per hour, the Poisson distribution predicts the likelihood of receiving exactly 15 calls in an hour.\n",
        "Traffic and Accidents Counting the number of car accidents on a highway per day. Predicting the number of people arriving at a hospital emergency room per hour.\n",
        "10. What is a continuous uniform distribution?\n",
        "A continuous uniform distribution is a probability distribution in which all outcomes within a given range [ùëé,ùëè][a,b] are equally likely. It is often denoted as U(a, b). Properties of the Continuous Uniform Distribution:\n",
        "\n",
        "Probability Density Function (PDF)\n",
        "[ f(x) =\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "Cumulative Distribution Function (CDF)\n",
        "[ F(x) =\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "Mean and Variance\n",
        "[ E[X] = \\frac{a + b}{2} ] [ \\text{Var}(X) = \\frac{(b - a)^2}{12} ]\n",
        "\n",
        "11. What are the characteristics of a normal distribution?\n",
        "Characteristics of a Normal Distribution A normal distribution, also known as a Gaussian distribution, is a continuous probability distribution that is symmetric and bell-shaped. It is widely used in statistics and real-world applications.\n",
        "\n",
        "Probability Density Function (PDF) The PDF of a normal distribution is given by: where: Œº = Mean (center of the distribution)ùúé œÉ = Standard deviation (spread of the distribution) ùúé2 = Variance ùëí = Euler‚Äôs number (‚âà2.7188) ùúã = Pi (‚âà3.1416)\n",
        "Symmetry The normal distribution is perfectly symmetric about its mean ùúá Œº. The left and right halves of the curve are mirror images.\n",
        "Mean, Median, and Mode are Equal In a normal distribution, the mean, median, and mode all occur at the same point: ùúá Œº.\n",
        "Bell-Shaped Curve The curve is bell-shaped, meaning most values cluster around the mean, and fewer values appear as you move away from it.\n",
        "Empirical Rule (68-95-99.7 Rule) About 68% of the data falls within 1 standard deviation (ùúá¬±ùúéŒº¬±œÉ). About 95% of the data falls within 2 standard deviations (ùúá¬±2ùúéŒº¬±2œÉ). About 99.7% of the data falls within 3 standard deviations (ùúá¬±3ùúéŒº¬±3œÉ).\n",
        "Asymptotic Nature The normal curve never touches the x-axis; it extends indefinitely in both directions.\n",
        "Defined by Two Parameters A normal distribution is completely defined by its mean (Œº) and standard deviation (œÉ).\n",
        "12. What is the standard normal distribution, and why is it important?\n",
        "The standard normal distribution is a bell-shaped curve where:\n",
        "\n",
        "The center is at 0 (mean = 0). The spread is measured using the standard deviation, which is 1. The total area under the curve is 1, meaning it represents 100% of probabilities. Key Properties: Symmetric Around 0 ‚Üí The left and right sides are mirror images. Most Values Close to 0 ‚Üí Data is concentrated around the center. Follows the 68-95-99.7 Rule ‚Üí Most values fall within 3 standard deviations.\n",
        "\n",
        "Why is it Important? Used to Compare Different Datasets ‚Äì Any normal dataset can be transformed into a standard form. Simplifies Probability Calculations ‚Äì Probabilities can be looked up in a Z-table instead of complex calculations. Widely Used in Statistics & Machine Learning ‚Äì Essential for hypothesis testing, confidence intervals, and data standardization.\n",
        "\n",
        "13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "Central Limit Theorem (CLT) and Its Importance\n",
        "The Central Limit Theorem (CLT) states that when you take many random samples from any population (regardless of its original shape), the average of those samples will follow a normal distribution as the sample size increases.\n",
        "\n",
        "In simple terms: ‚úÖ Any data, no matter how skewed, becomes normal when averaged over many samples.\n",
        "\n",
        "Why is CLT Important? üîπ Works for Any Population ‚Üí Even if the original data is not normal, the sample means will be. üîπ Enables Statistical Inference ‚Üí We can make predictions about a population using sample data. üîπ Foundation for Many Tests ‚Üí Essential for hypothesis testing, confidence intervals, and machine learning models. üîπ Real-World Applications ‚Üí Used in polling, quality control, finance, and AI to analyze large datasets.\n",
        "\n",
        "14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "The Central Limit Theorem (CLT) explains why the normal distribution appears so frequently in statistics. It states that:\n",
        "\n",
        "‚úÖ When we take many random samples from any population, the distribution of sample means will be approximately normal‚Äîregardless of the shape of the original population.\n",
        "\n",
        "Key Relationships Between CLT and the Normal Distribution:\n",
        "Converts Any Distribution into Normal\n",
        "\n",
        "Even if the original population is skewed, uniform, or multimodal, the CLT ensures that the sample means follow a normal distribution when the sample size is large enough. Larger Sample Sizes Lead to a More Normal Shape\n",
        "\n",
        "The more data points in each sample, the closer the sample mean distribution gets to a perfect normal curve. A sample size of 30 or more is often enough for CLT to hold. Explains Why the Normal Distribution is Common in Nature\n",
        "\n",
        "Many real-world processes (e.g., height, IQ, errors in measurements) follow a normal distribution because they result from the combination of many small random influences‚Äîjust as CLT predicts. Forms the Basis for Statistical Inference\n",
        "\n",
        "Since sample means follow a normal distribution, we can apply Z-tests, T-tests, and confidence intervals to make conclusions about an entire population using just a sample.\n",
        "\n",
        "15. What is the application of Z statistics in hypothesis testing?\n",
        "Z-statistics (or Z-scores) are widely used in hypothesis testing, particularly in cases where the population standard deviation is known or the sample size is large (typicallyn‚â•30). Here are the key applications:\n",
        "\n",
        "Testing Population Means\n",
        "Used in one-sample Z-tests to compare a sample mean to a known population mean. Applied in two-sample Z-tests to compare the means of two independent populations.\n",
        "\n",
        "Testing Population Proportions\n",
        "Used in one-proportion Z-tests to determine if a sample proportion significantly differs from a known population proportion. Used in two-proportion Z-tests to compare the proportions of two independent groups.\n",
        "\n",
        "Confidence Intervals\n",
        "Z-statistics help construct confidence intervals for population means and proportions.\n",
        "\n",
        "Quality Control and Industrial Applications\n",
        "Used in statistical process control (SPC) to monitor production quality.\n",
        "\n",
        "Medical and Pharmaceutical Studies\n",
        "Applied in clinical trials to test the efficacy of treatments when population parameters are known.\n",
        "\n",
        "16. How do you calculate a Z-score, and what does it represent?\n",
        "The Z-score (or standard score) is calculated using the formula:\n",
        "\n",
        "Where: X = observed value ùúá Œº = population mean ùúé œÉ = population standard deviation For a sample-based Z-score (if the population standard deviation is unknown and sample size is large (n‚â•30):\n",
        "\n",
        "\n",
        "\n",
        "What Does a Z-score Represent?\n",
        "A Z-score indicates how many standard deviations an individual data point or sample mean is from the population mean. It helps in:\n",
        "\n",
        "Standardization ‚Äì Allows comparison of different distributions. Outlier Detection ‚Äì Extreme Z-scores (e.g., beyond ¬±2 or ¬±3) may indicate outliers. Probability Estimation ‚Äì Helps find probabilities in a normal distribution using Z-tables.\n",
        "\n",
        "17. What are point estimates and interval estimates in statistics?\n",
        "In statistics, point estimates and interval estimates are two fundamental approaches used to infer population parameters based on sample data.\n",
        "\n",
        "Point Estimates\n",
        "\n",
        "A point estimate provides a single value as an approximation of an unknown population parameter. This value is derived from sample data and serves as the best guess for the parameter in question. Common examples include:\n",
        "\n",
        "Sample Mean ( ùëã Àâ X Àâ ): Used to estimate the population mean (Œº). Sample Proportion (pÃÇ): Used to estimate the population proportion (P). For instance, if we collect a random sample of individuals' heights and calculate the average height, this sample mean acts as a point estimate of the overall population mean height. STAT TREK\n",
        "\n",
        "Interval Estimates\n",
        "\n",
        "An interval estimate, on the other hand, provides a range of values within which the unknown population parameter is expected to lie. This range acknowledges the inherent variability and uncertainty present in sample data. The most common form of interval estimation is the confidence interval, which is typically expressed with a certain confidence level (e.g., 95%).\n",
        "\n",
        "For example, a 95% confidence interval for a population mean might be calculated as (Œº - E, Œº + E), where E represents the margin of error. This interval suggests that we can be 95% confident that the true population mean falls within this range.\n",
        "\n",
        "18. What is the significance of confidence intervals in statistical analysis?\n",
        "Confidence intervals (CIs) are fundamental tools in statistical analysis, offering a range within which we expect a population parameter to lie, based on sample data. Their significance includes:\n",
        "\n",
        "Quantifying Uncertainty: CIs provide a measure of the precision of an estimate. A narrower interval indicates higher precision, while a wider interval suggests greater uncertainty.\n",
        "\n",
        "Relating to Statistical Significance: CIs are closely linked to hypothesis testing. For example, if a 95% CI for a mean difference excludes zero, it suggests that the observed effect is statistically significant at the 5% significance level. BMJ\n",
        "\n",
        "Informing Decision-Making: By indicating the range of plausible values for a parameter, CIs assist researchers and policymakers in making informed decisions, considering both the estimate and its associated uncertainty.\n",
        "\n",
        "Enhancing Transparency: Reporting CIs alongside point estimates offers a more comprehensive view of the data, promoting transparency and aiding in the interpretation of results.\n",
        "\n",
        "19. What is the relationship between a Z-score and a confidence interval?\n",
        "In statistical analysis, Z-scores and confidence intervals are closely related, particularly when estimating population parameters like the mean. The Z-score, often referred to as the critical value (denoted as ZŒ±/2), determines the number of standard deviations a data point is from the mean and is pivotal in constructing confidence intervals.\n",
        "\n",
        "Constructing Confidence Intervals Using Z-Scores\n",
        "\n",
        "For a population with a known standard deviation (œÉ) and a sample mean (xÃÑ), the formula for a confidence interval (CI) for the population mean (Œº) is:\n",
        "\n",
        "CI = xÃÑ ¬± ZŒ±/2 √ó (œÉ/‚àön)\n",
        "\n",
        "Where:\n",
        "\n",
        "ZŒ±/2 is the Z-score corresponding to the desired confidence level. œÉ is the population standard deviation. n is the sample size. The Z-score (ZŒ±/2) is selected based on the desired confidence level:\n",
        "\n",
        "90% Confidence Level: Z0.05 ‚âà 1.645 95% Confidence Level: Z0.025 ‚âà 1.96 99% Confidence Level: Z0.005 ‚âà 2.576 These values are derived from the standard normal distribution and indicate the number of standard deviations required to capture the central percentage of interest.\n",
        "\n",
        "20. How are Z-scores used to compare different distributions?\n",
        "Z-scores, or standard scores, are statistical measures that indicate how many standard deviations an individual data point is from the mean of its distribution. They are particularly useful for comparing data points from different distributions, as they standardize values, allowing for direct comparison regardless of the original scales or units.\n",
        "\n",
        "Calculation of Z-Score\n",
        "\n",
        "The Z-score for a data point x is calculated using the formula:\n",
        "\n",
        "Where: X = observed value ùúá Œº = population mean ùúé œÉ = population standard deviation Comparing Different Distributions Using Z-Scores\n",
        "\n",
        "By converting data points from different distributions into Z-scores, we can assess their relative standings within their respective distributions. This standardization enables meaningful comparisons between data sets that may have different means and standard deviations.\n",
        "\n",
        "Example\n",
        "\n",
        "Consider two students who took different standardized tests:\n",
        "\n",
        "Student A: Scored 85 on Test A, which has a mean (Œº) of 80 and a standard deviation (œÉ) of 5. Student B: Scored 90 on Test B, which has a mean (Œº) of 85 and a standard deviation (œÉ) of 10. Calculating the Z-scores: Student A: ùëç=85‚àí80/5=1 Student B: ùëç=90‚àí85/10=0.5 Interpretation:\n",
        "\n",
        "Student A's score is 1 standard deviation above the mean of Test A. Student B's score is 0.5 standard deviations above the mean of Test B. Despite Student B having a higher raw score, Student A performed better relative to their respective test populations. This comparison is facilitated by standardizing the scores using Z-scores.\n",
        "\n",
        "21. What are the assumptions for applying the Central Limit Theorem?\n",
        "The Central Limit Theorem (CLT) states that, for a sufficiently large sample size, the distribution of the sample mean approaches a normal distribution, regardless of the population's original distribution. However, CLT is valid under certain assumptions:\n",
        "\n",
        "Key Assumptions of the Central Limit Theorem: Random Sampling The data should be collected using a random sampling method to ensure unbiased representation of the population.\n",
        "\n",
        "Independence of Observations Each observation should be independent of others. This means that the selection of one sample does not affect another. If sampling without replacement, the population should be at least 10 times larger than the sample size (the 10% condition) to approximate independence.\n",
        "\n",
        "Identically Distributed Data The observations should come from the same distribution with the same mean (Œº) and variance (œÉ¬≤).\n",
        "\n",
        "Sufficiently Large Sample Size The sample size n should be large enough (typically n ‚â• 30) for the CLT to hold. If the population is normally distributed, then CLT holds even for small sample sizes. If the population is highly skewed, larger sample sizes (n > 30 or even n > 50) may be required.\n",
        "\n",
        "Finite Variance The population must have a finite standard deviation (œÉ¬≤) to ensure the sample mean does not become unstable.\n",
        "\n",
        "22. What is the concept of expected value in a probability distribution?\n",
        "Concept of Expected Value in a Probability Distribution The expected value (EV) is the average outcome you would expect over a large number of trials in a probability experiment. It represents the theoretical long-run mean of a random variable and helps in understanding the central tendency of a probability distribution.\n",
        "\n",
        "Understanding Expected Value with Examples Rolling a Die üé≤\n",
        "\n",
        "If you roll a fair six-sided die multiple times, the expected value tells you the average result you‚Äôd get over time. Even though you can‚Äôt roll a 3.5, over thousands of rolls, the average outcome approaches that value. Lottery or Gambling üí∞\n",
        "\n",
        "In a lottery, the expected value helps determine the average amount a player wins or loses per ticket purchased. If the expected value is negative, it means the game is designed for long-term loss.\n",
        "\n",
        "23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "Relationship Between a Probability Distribution and the Expected Outcome A probability distribution describes how likely different values of a random variable are to occur. The expected outcome, also called the expected value, represents the long-term average of the random variable when repeated many times. How They Are Connected\n",
        "\n",
        "Probability Weights Outcomes Each possible value of a random variable has an associated probability in the distribution. The expected outcome depends on both the values and their probabilities‚Äîmore likely values contribute more to the expected outcome.\n",
        "\n",
        "Averages Over Time If an experiment (like rolling a die) is repeated many times, the actual average outcome will approximate the expected value given by the probability distribution.\n",
        "\n",
        "Different Distributions, Different Expectations In a fair die roll, all outcomes are equally likely, leading to an average result near the middle. In skewed distributions (like wealth distribution), the expected value may not be in the middle but pulled toward more frequent or extreme values.\n",
        "\n",
        "                                                            PRACTICAL QUESTIONS\n",
        "# 1. Write a Python program to generate a random variable and display its value?\n",
        "import random\n",
        "\n",
        "# Generate a random integer between 1 and 100\n",
        "random_variable = random.randint(1, 100)\n",
        "\n",
        "# Display the random variable\n",
        "print(\"Generated Random Variable:\", random_variable)\n",
        "Generated Random Variable: 56\n",
        "#2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define parameters for the discrete uniform distribution\n",
        "low, high = 1, 6  # Example: Rolling a fair 6-sided die\n",
        "\n",
        "# Generate discrete values in the range\n",
        "x = np.arange(low, high + 1)\n",
        "\n",
        "# Compute the PMF (each outcome has equal probability)\n",
        "pmf = stats.randint.pmf(x, low, high + 1)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.bar(x, pmf, color='blue', alpha=0.7, edgecolor='black')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Random Variable (X)\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"PMF of a Discrete Uniform Distribution\")\n",
        "\n",
        "# Show values on bars\n",
        "for i, p in zip(x, pmf):\n",
        "    plt.text(i, p + 0.01, f\"{p:.2f}\", ha='center')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# 3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution?\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def bernoulli_pdf(p):\n",
        "    \"\"\"\n",
        "    Function to compute and plot the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "\n",
        "    Parameters:\n",
        "    p (float): Probability of success (0 ‚â§ p ‚â§ 1)\n",
        "    \"\"\"\n",
        "    # Possible values for a Bernoulli random variable: 0 (failure) and 1 (success)\n",
        "    x = [0, 1]\n",
        "\n",
        "    # Compute the probability mass function (PMF) using scipy.stats\n",
        "    pmf = stats.bernoulli.pmf(x, p)\n",
        "\n",
        "    # Plot the PMF (since Bernoulli is discrete, we use bar chart)\n",
        "    plt.bar(x, pmf, color=['red', 'green'], alpha=0.7, edgecolor='black')\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xticks([0, 1], [\"Failure (0)\", \"Success (1)\"])\n",
        "    plt.xlabel(\"Random Variable (X)\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(f\"Bernoulli Distribution (p = {p})\")\n",
        "\n",
        "    # Show probability values on bars\n",
        "    for i, prob in zip(x, pmf):\n",
        "        plt.text(i, prob + 0.02, f\"{prob:.2f}\", ha='center')\n",
        "\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with p = 0.6\n",
        "bernoulli_pdf(0.6)\n",
        "\n",
        " # 4.Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Parameters for the binomial distribution\n",
        "n = 10   # Number of trials\n",
        "p = 0.5  # Probability of success in each trial\n",
        "size = 10000  # Number of simulations\n",
        "\n",
        "# Simulate binomial distribution\n",
        "data = np.random.binomial(n, p, size)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(data, bins=np.arange(n+2)-0.5, density=True, alpha=0.7, color='blue', edgecolor='black')\n",
        "\n",
        "# Overlay the theoretical binomial PMF\n",
        "x = np.arange(0, n+1)\n",
        "pmf = stats.binom.pmf(x, n, p)\n",
        "plt.plot(x, pmf, 'ro-', label=\"Theoretical PMF\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Number of Successes\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(f\"Binomial Distribution (n={n}, p={p})\")\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        " # 5.Create a Poisson distribution and visualize it using Python?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define Poisson distribution parameter (Œª = average number of events per interval)\n",
        "lam = 4  # Example: Average of 4 events per unit time\n",
        "\n",
        "# Generate Poisson-distributed data\n",
        "x = np.arange(0, 15)  # Possible values (0 to 14)\n",
        "pmf = stats.poisson.pmf(x, lam)  # Compute probability mass function (PMF)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.bar(x, pmf, color='purple', alpha=0.7, edgecolor='black')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Number of Events (X)\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(f\"Poisson Distribution (Œª={lam})\")\n",
        "\n",
        "# Show probability values on bars\n",
        "for i, p in zip(x, pmf):\n",
        "    plt.text(i, p + 0.01, f\"{p:.2f}\", ha='center')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# 6 Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define parameters for the discrete uniform distribution\n",
        "low, high = 1, 6  # Example: Rolling a fair 6-sided die\n",
        "\n",
        "# Generate possible values\n",
        "x = np.arange(low, high + 1)\n",
        "\n",
        "# Compute the CDF using scipy.stats\n",
        "cdf = stats.randint.cdf(x, low, high + 1)\n",
        "\n",
        "# Plot the CDF\n",
        "plt.step(x, cdf, where='mid', color='blue', label=\"CDF\", linewidth=2)\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Random Variable (X)\")\n",
        "plt.ylabel(\"Cumulative Probability\")\n",
        "plt.title(\"CDF of a Discrete Uniform Distribution\")\n",
        "\n",
        "# Show probability values at points\n",
        "for i, p in zip(x, cdf):\n",
        "    plt.text(i, p - 0.05, f\"{p:.2f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.xticks(x)  # Ensure x-axis labels match discrete values\n",
        "plt.yticks(np.linspace(0, 1, len(x)))  # Set y-axis scale from 0 to 1\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 7. Generate a continuous uniform distribution using NumPy and visualize it?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define parameters for the continuous uniform distribution\n",
        "low, high = 0, 10  # Example: Uniform distribution between 0 and 10\n",
        "\n",
        "# Generate random samples from the uniform distribution\n",
        "samples = np.random.uniform(low, high, 10000)\n",
        "\n",
        "# Generate values for the PDF plot\n",
        "x = np.linspace(low, high, 1000)\n",
        "pdf = stats.uniform.pdf(x, low, high - low)  # Compute PDF\n",
        "\n",
        "# Plot histogram of generated samples\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.6, color='blue', edgecolor='black', label=\"Simulated Data\")\n",
        "\n",
        "# Overlay the theoretical PDF\n",
        "plt.plot(x, pdf, 'r-', linewidth=2, label=\"Theoretical PDF\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Random Variable (X)\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.title(\"Continuous Uniform Distribution\")\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        " # 8. Simulate data from a normal distribution and plot its histogram?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define parameters for the normal distribution\n",
        "mean = 0      # Mean (center of the distribution)\n",
        "std_dev = 1   # Standard deviation (spread of the distribution)\n",
        "size = 10000  # Number of random samples\n",
        "\n",
        "# Generate random samples from the normal distribution\n",
        "samples = np.random.normal(mean, std_dev, size)\n",
        "\n",
        "# Generate values for the theoretical normal PDF\n",
        "x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "pdf = stats.norm.pdf(x, mean, std_dev)\n",
        "\n",
        "# Plot histogram of generated samples\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.6, color='blue', edgecolor='black', label=\"Simulated Data\")\n",
        "\n",
        "# Overlay the theoretical PDF\n",
        "plt.plot(x, pdf, 'r-', linewidth=2, label=\"Theoretical PDF\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Random Variable (X)\")\n",
        "plt.ylabel(\"Probability Density\")\n",
        "plt.title(\"Histogram of Simulated Normal Distribution\")\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# 9 Write a Python function to calculate Z-scores from a dataset and plot them?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Function to calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "    Parameters:\n",
        "    data (list or numpy array): Input dataset.\n",
        "\n",
        "    Returns:\n",
        "    z_scores (numpy array): Computed Z-scores.\n",
        "    \"\"\"\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data, ddof=1)  # Using sample standard deviation\n",
        "\n",
        "    # Compute Z-scores\n",
        "    z_scores = (data - mean) / std_dev\n",
        "\n",
        "    # Plot Z-scores\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(z_scores, bins=20, kde=True, color='blue', edgecolor='black', alpha=0.6)\n",
        "\n",
        "    # Add mean and standard deviation reference lines\n",
        "    plt.axvline(0, color='red', linestyle='dashed', label=\"Mean (0)\")\n",
        "    plt.axvline(-1, color='gray', linestyle='dotted', label=\"1 Std Dev\")\n",
        "    plt.axvline(1, color='gray', linestyle='dotted')\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"Z-score\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Histogram of Z-scores\")\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "# Example usage with simulated normal data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)  # Generate random dataset\n",
        "z_scores = calculate_and_plot_z_scores(data)\n",
        "\n",
        "# 10 Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def clt_simulation(population_dist, sample_size=30, num_samples=1000):\n",
        "    \"\"\"\n",
        "    Simulates the Central Limit Theorem by drawing random samples from a non-normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    population_dist (numpy array): The original non-normal population distribution.\n",
        "    sample_size (int): The size of each random sample.\n",
        "    num_samples (int): The number of sample means to compute.\n",
        "\n",
        "    Returns:\n",
        "    None (plots the distributions).\n",
        "    \"\"\"\n",
        "    sample_means = []\n",
        "\n",
        "    # Generate sample means\n",
        "    for _ in range(num_samples):\n",
        "        sample = np.random.choice(population_dist, sample_size, replace=True)\n",
        "        sample_means.append(np.mean(sample))\n",
        "\n",
        "    # Plot the original non-normal population distribution\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(population_dist, bins=50, kde=True, color='blue', edgecolor='black', alpha=0.6)\n",
        "    plt.title(\"Original Non-Normal Population Distribution\")\n",
        "    plt.xlabel(\"Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    # Plot the distribution of sample means\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(sample_means, bins=30, kde=True, color='red', edgecolor='black', alpha=0.6)\n",
        "    plt.title(f\"Sampling Distribution of Sample Means (n={sample_size})\")\n",
        "    plt.xlabel(\"Sample Mean\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate a non-normal population distribution (Exponential Distribution)\n",
        "np.random.seed(42)\n",
        "population_data = np.random.exponential(scale=2, size=10000)  # Highly skewed distribution\n",
        "\n",
        "# Apply the CLT with a sample size of 30\n",
        "clt_simulation(population_data, sample_size=30, num_samples=1000)\n",
        "\n",
        "# 11 Simulate multiple samples from a normal distribution and verify the Central Limit Theorem?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def clt_normal_distribution(mean=50, std_dev=15, population_size=10000, sample_size=30, num_samples=1000):\n",
        "    \"\"\"\n",
        "    Simulates the Central Limit Theorem using a normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    mean (float): Mean of the normal population.\n",
        "    std_dev (float): Standard deviation of the normal population.\n",
        "    population_size (int): Number of data points in the original population.\n",
        "    sample_size (int): Size of each random sample.\n",
        "    num_samples (int): Number of sample means to compute.\n",
        "\n",
        "    Returns:\n",
        "    None (plots the distributions).\n",
        "    \"\"\"\n",
        "    # Generate a normal population\n",
        "    population_data = np.random.normal(mean, std_dev, population_size)\n",
        "\n",
        "    # Generate sample means\n",
        "    sample_means = [np.mean(np.random.choice(population_data, sample_size, replace=True)) for _ in range(num_samples)]\n",
        "\n",
        "    # Plot the original normal population distribution\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(population_data, bins=50, kde=True, color='blue', edgecolor='black', alpha=0.6)\n",
        "    plt.title(\"Original Normal Population Distribution\")\n",
        "    plt.xlabel(\"Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    # Plot the distribution of sample means\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(sample_means, bins=30, kde=True, color='red', edgecolor='black', alpha=0.6)\n",
        "    plt.title(f\"Sampling Distribution of Sample Means (n={sample_size})\")\n",
        "    plt.xlabel(\"Sample Mean\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the simulation\n",
        "np.random.seed(42)  # For reproducibility\n",
        "clt_normal_distribution()\n",
        "\n",
        "# 12 Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1)?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "    \"\"\"\n",
        "    Function to calculate and plot the standard normal distribution (mean=0, std=1).\n",
        "    \"\"\"\n",
        "    # Generate values from -4 to 4 (covering most of the normal curve)\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "\n",
        "    # Compute the Probability Density Function (PDF) of standard normal distribution\n",
        "    pdf = stats.norm.pdf(x, 0, 1)\n",
        "\n",
        "    # Plot the standard normal distribution\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, pdf, 'b-', linewidth=2, label=\"Standard Normal PDF\")\n",
        "\n",
        "    # Add mean and standard deviation reference lines\n",
        "    plt.axvline(0, color='red', linestyle='dashed', label=\"Mean (0)\")\n",
        "    plt.axvline(-1, color='gray', linestyle='dotted', label=\"1 Std Dev (-1)\")\n",
        "    plt.axvline(1, color='gray', linestyle='dotted', label=\"1 Std Dev (1)\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"X (Standard Normal Variable)\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.title(\"Standard Normal Distribution (Œº=0, œÉ=1)\")\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_standard_normal_distribution()\n",
        "\n",
        "# 13 Generate random variables and calculate their corresponding probabilities using the binomial distribution?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def binomial_distribution_simulation(n=10, p=0.5, size=1000):\n",
        "    \"\"\"\n",
        "    Generates random variables from a binomial distribution and calculates probabilities.\n",
        "\n",
        "    Parameters:\n",
        "    n (int): Number of trials.\n",
        "    p (float): Probability of success in each trial.\n",
        "    size (int): Number of random variables to generate.\n",
        "    \"\"\"\n",
        "    # Generate binomial random variables\n",
        "    random_variables = np.random.binomial(n, p, size)\n",
        "\n",
        "    # Compute the theoretical probabilities (PMF)\n",
        "    x = np.arange(0, n + 1)  # Possible outcomes from 0 to n\n",
        "    pmf_values = stats.binom.pmf(x, n, p)\n",
        "\n",
        "    # Plot histogram of generated binomial random variables\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(random_variables, bins=n+1, density=True, alpha=0.6, color='blue', edgecolor='black', label=\"Simulated Data\")\n",
        "\n",
        "    # Overlay the theoretical PMF\n",
        "    plt.plot(x, pmf_values, 'ro-', markersize=8, label=\"Theoretical PMF\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"Number of Successes (X)\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(f\"Binomial Distribution (n={n}, p={p})\")\n",
        "    plt.xticks(range(n+1))\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "    return random_variables\n",
        "\n",
        "# Run the simulation\n",
        "np.random.seed(42)  # For reproducibility\n",
        "random_vars = binomial_distribution_simulation(n=10, p=0.5, size=1000)\n",
        "\n",
        "# 14 Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def calculate_z_score(data, x_value):\n",
        "    \"\"\"\n",
        "    Calculates the Z-score for a given data point and compares it to a standard normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): The dataset to compute mean and standard deviation.\n",
        "    x_value (float): The specific data point to calculate the Z-score.\n",
        "\n",
        "    Returns:\n",
        "    float: The Z-score of the given data point.\n",
        "    \"\"\"\n",
        "    # Calculate mean and standard deviation\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data, ddof=1)  # Using sample standard deviation\n",
        "\n",
        "    # Compute Z-score\n",
        "    z_score = (x_value - mean) / std_dev\n",
        "\n",
        "    # Generate standard normal distribution\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    pdf = stats.norm.pdf(x, 0, 1)\n",
        "\n",
        "    # Plot standard normal distribution\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, pdf, 'b-', linewidth=2, label=\"Standard Normal PDF\")\n",
        "\n",
        "    # Mark the Z-score location\n",
        "    plt.axvline(z_score, color='red', linestyle='dashed', label=f\"Z-score = {z_score:.2f}\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"Z-score\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.title(\"Comparison of Z-score with Standard Normal Distribution\")\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "    return z_score\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=1000)  # Generate random dataset\n",
        "x_value = 65  # Data point to calculate Z-score\n",
        "\n",
        "# Calculate and plot Z-score\n",
        "z = calculate_z_score(sample_data, x_value)\n",
        "print(f\"Z-score for X = {x_value}: {z:.2f}\")\n",
        "\n",
        "Z-score for X = 65: 1.51\n",
        "# 15 Implement hypothesis testing using Z-statistics for a sample dataset?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def z_test(sample, population_mean, population_std, alpha=0.05, alternative=\"two-tailed\"):\n",
        "    \"\"\"\n",
        "    Performs a hypothesis test using Z-statistics.\n",
        "\n",
        "    Parameters:\n",
        "    sample (array-like): Sample dataset.\n",
        "    population_mean (float): Population mean (H0).\n",
        "    population_std (float): Population standard deviation (œÉ).\n",
        "    alpha (float): Significance level (default=0.05).\n",
        "    alternative (str): \"two-tailed\", \"greater\", or \"less\".\n",
        "\n",
        "    Returns:\n",
        "    None (prints the test results).\n",
        "    \"\"\"\n",
        "    # Sample size, mean\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    # Compute Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "\n",
        "    # Compute p-value\n",
        "    if alternative == \"two-tailed\":\n",
        "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # Two-tailed test\n",
        "    elif alternative == \"greater\":\n",
        "        p_value = 1 - stats.norm.cdf(z_score)  # Right-tailed test\n",
        "    elif alternative == \"less\":\n",
        "        p_value = stats.norm.cdf(z_score)  # Left-tailed test\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-tailed', 'greater', or 'less'\")\n",
        "\n",
        "    # Determine result\n",
        "    print(f\"Z-score: {z_score:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        print(\"Reject the null hypothesis (H0). Significant evidence for Ha.\")\n",
        "    else:\n",
        "        print(\"Fail to reject the null hypothesis (H0). No significant evidence for Ha.\")\n",
        "\n",
        "# Example dataset\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=51, scale=10, size=50)  # Sample from normal distribution\n",
        "\n",
        "# Run Z-test\n",
        "z_test(sample=sample_data, population_mean=50, population_std=10, alpha=0.05, alternative=\"two-tailed\")\n",
        "Z-score: -0.8872\n",
        "P-value: 0.3750\n",
        "Fail to reject the null hypothesis (H0). No significant evidence for Ha.\n",
        "# 16 Create a confidence interval for a dataset using Python and interpret the result?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def confidence_interval(sample, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    Computes the confidence interval for a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    sample (array-like): The dataset (sample).\n",
        "    confidence_level (float): The confidence level (default=0.95).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Lower and upper bounds of the confidence interval.\n",
        "    \"\"\"\n",
        "    # Sample size, mean, and standard deviation\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # Sample standard deviation\n",
        "\n",
        "    # Compute the critical Z-value\n",
        "    z_value = stats.norm.ppf((1 + confidence_level) / 2)  # Two-tailed Z-score\n",
        "\n",
        "    # Compute margin of error\n",
        "    margin_of_error = z_value * (sample_std / np.sqrt(n))\n",
        "\n",
        "    # Compute confidence interval\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    print(f\"{confidence_level*100}% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example dataset\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=100)  # Sample from normal distribution\n",
        "\n",
        "# Compute 95% confidence interval\n",
        "confidence_interval(sample_data, confidence_level=0.95)\n",
        "95.0% Confidence Interval: (47.18, 50.74)\n",
        "(np.float64(47.18155741526743), np.float64(50.74151223685072))\n",
        "# 17 Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def confidence_interval(sample, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    Computes and visualizes the confidence interval for a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    sample (array-like): The dataset (sample).\n",
        "    confidence_level (float): The confidence level (default=0.95).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Lower and upper bounds of the confidence interval.\n",
        "    \"\"\"\n",
        "    # Sample statistics\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # Sample standard deviation\n",
        "\n",
        "    # Compute critical Z-value\n",
        "    z_value = stats.norm.ppf((1 + confidence_level) / 2)  # Two-tailed Z-score\n",
        "\n",
        "    # Compute margin of error\n",
        "    margin_of_error = z_value * (sample_std / np.sqrt(n))\n",
        "\n",
        "    # Confidence interval\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    # Print result\n",
        "    print(f\"{confidence_level*100}% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(sample, bins=20, alpha=0.7, color='blue', edgecolor='black', density=True, label=\"Sample Data\")\n",
        "    plt.axvline(sample_mean, color='red', linestyle='dashed', label=f\"Mean = {sample_mean:.2f}\")\n",
        "    plt.axvline(lower_bound, color='green', linestyle='dashed', label=f\"Lower Bound = {lower_bound:.2f}\")\n",
        "    plt.axvline(upper_bound, color='green', linestyle='dashed', label=f\"Upper Bound = {upper_bound:.2f}\")\n",
        "\n",
        "    plt.xlabel(\"Value\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.title(f\"{confidence_level*100}% Confidence Interval for the Mean\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.4)\n",
        "    plt.show()\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Generate normal data\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=10, size=100)  # Normal distribution with Œº=50, œÉ=10\n",
        "\n",
        "# Compute and plot 95% confidence interval\n",
        "confidence_interval(sample_data, confidence_level=0.95)\n",
        "95.0% Confidence Interval: (47.18, 50.74)\n",
        "\n",
        "(np.float64(47.18155741526743), np.float64(50.74151223685072))\n",
        "# 18 Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "def plot_normal_pdf(mean=0, std_dev=1):\n",
        "    \"\"\"\n",
        "    Plots the probability density function (PDF) of a normal distribution.\n",
        "\n",
        "    Parameters:\n",
        "    mean (float): Mean (Œº) of the normal distribution.\n",
        "    std_dev (float): Standard deviation (œÉ) of the normal distribution.\n",
        "    \"\"\"\n",
        "    # Generate x values (range covering ¬±4œÉ)\n",
        "    x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "\n",
        "    # Compute PDF using scipy.stats\n",
        "    pdf_values = stats.norm.pdf(x, mean, std_dev)\n",
        "\n",
        "    # Plot PDF\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(x, pdf_values, 'b-', linewidth=2, label=f\"Normal(Œº={mean}, œÉ={std_dev})\")\n",
        "\n",
        "    # Mark mean and standard deviation\n",
        "    plt.axvline(mean, color='red', linestyle='dashed', label=f\"Mean (Œº) = {mean}\")\n",
        "    plt.axvline(mean - std_dev, color='green', linestyle='dotted', label=f\"Œº - œÉ\")\n",
        "    plt.axvline(mean + std_dev, color='green', linestyle='dotted', label=f\"Œº + œÉ\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"X values\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.title(\"Probability Density Function (PDF) of a Normal Distribution\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage: Standard normal distribution (mean=0, std_dev=1)\n",
        "plot_normal_pdf(mean=0, std_dev=1)\n",
        "\n",
        " # 19 Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution?\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def poisson_cdf(lambda_value, max_k=20):\n",
        "    \"\"\"\n",
        "    Computes and visualizes the CDF of a Poisson distribution.\n",
        "\n",
        "    Parameters:\n",
        "    lambda_value (float): The mean number of events (Œª).\n",
        "    max_k (int): The maximum value of k to compute the CDF.\n",
        "\n",
        "    Returns:\n",
        "    None (prints probabilities and plots the CDF).\n",
        "    \"\"\"\n",
        "    # Generate k values (discrete points)\n",
        "    k_values = np.arange(0, max_k + 1)\n",
        "\n",
        "    # Compute CDF values\n",
        "    cdf_values = stats.poisson.cdf(k_values, mu=lambda_value)\n",
        "\n",
        "    # Print CDF values\n",
        "    for k, cdf in zip(k_values, cdf_values):\n",
        "        print(f\"P(X ‚â§ {k}) = {cdf:.4f}\")\n",
        "\n",
        "    # Plot the CDF\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.step(k_values, cdf_values, where='post', color='b', label=f\"Poisson CDF (Œª={lambda_value})\")\n",
        "\n",
        "    # Mark specific values for interpretation\n",
        "    plt.axhline(0.5, color='red', linestyle='dashed', label=\"50% Probability\")\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"Number of Events (k)\")\n",
        "    plt.ylabel(\"Cumulative Probability (P(X ‚â§ k))\")\n",
        "    plt.title(\"Cumulative Distribution Function (CDF) of a Poisson Distribution\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with Œª=5\n",
        "poisson_cdf(lambda_value=5, max_k=20)\n",
        "P(X ‚â§ 0) = 0.0067\n",
        "P(X ‚â§ 1) = 0.0404\n",
        "P(X ‚â§ 2) = 0.1247\n",
        "P(X ‚â§ 3) = 0.2650\n",
        "P(X ‚â§ 4) = 0.4405\n",
        "P(X ‚â§ 5) = 0.6160\n",
        "P(X ‚â§ 6) = 0.7622\n",
        "P(X ‚â§ 7) = 0.8666\n",
        "P(X ‚â§ 8) = 0.9319\n",
        "P(X ‚â§ 9) = 0.9682\n",
        "P(X ‚â§ 10) = 0.9863\n",
        "P(X ‚â§ 11) = 0.9945\n",
        "P(X ‚â§ 12) = 0.9980\n",
        "P(X ‚â§ 13) = 0.9993\n",
        "P(X ‚â§ 14) = 0.9998\n",
        "P(X ‚â§ 15) = 0.9999\n",
        "P(X ‚â§ 16) = 1.0000\n",
        "P(X ‚â§ 17) = 1.0000\n",
        "P(X ‚â§ 18) = 1.0000\n",
        "P(X ‚â§ 19) = 1.0000\n",
        "P(X ‚â§ 20) = 1.0000\n",
        "\n",
        "# 20 Simulate a random variable using a continuous uniform distribution and calculate its expected value?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def uniform_distribution_simulation(a, b, sample_size=1000):\n",
        "    \"\"\"\n",
        "    Simulates a continuous uniform distribution, calculates the expected value,\n",
        "    and visualizes the distribution.\n",
        "\n",
        "    Parameters:\n",
        "    a (float): Lower bound of the uniform distribution.\n",
        "    b (float): Upper bound of the uniform distribution.\n",
        "    sample_size (int): Number of random samples to generate.\n",
        "\n",
        "    Returns:\n",
        "    None (prints expected value and plots the histogram).\n",
        "    \"\"\"\n",
        "    # Generate random samples from U(a, b)\n",
        "    samples = np.random.uniform(a, b, sample_size)\n",
        "\n",
        "    # Calculate expected value (theoretical and sample mean)\n",
        "    expe# 21cted_value = (a + b) / 2\n",
        "    sample_mean = np.mean(samples)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Theoretical Expected Value: {expected_value:.2f}\")\n",
        "    print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(samples, bins=20, color='blue', alpha=0.7, edgecolor='black', density=True, label=\"Sampled Data\")\n",
        "    plt.axvline(expected_value, color='red', linestyle='dashed', linewidth=2, label=f\"Expected Value (E[X]) = {expected_value:.2f}\")\n",
        "    plt.xlabel(\"X values\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.title(f\"Continuous Uniform Distribution U({a}, {b})\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with U(10, 20)\n",
        "uniform_distribution_simulation(a=10, b=20, sample_size=1000)\n",
        "Theoretical Expected Value: 15.00\n",
        "Sample Mean: 14.98\n",
        "\n",
        "# 21 Write a Python program to compare the standard deviations of two datasets and visualize the difference?\n",
        "#The standard deviation (œÉ) measures the spread of data points around the mean. A higher standard deviation means more variability, while a lower standard deviation indicates that values are closer to the mean.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_standard_deviations(data1, data2):\n",
        "    \"\"\"\n",
        "    Compares the standard deviations of two datasets and visualizes them.\n",
        "\n",
        "    Parameters:\n",
        "    data1 (array-like): First dataset.\n",
        "    data2 (array-like): Second dataset.\n",
        "\n",
        "    Returns:\n",
        "    None (prints standard deviations and plots histograms).\n",
        "    \"\"\"\n",
        "    # Compute standard deviations\n",
        "    std1 = np.std(data1, ddof=1)\n",
        "    std2 = np.std(data2, ddof=1)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Standard Deviation of Dataset 1: {std1:.2f}\")\n",
        "    print(f\"Standard Deviation of Dataset 2: {std2:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.hist(data1, bins=20, alpha=0.6, color='blue', edgecolor='black', label=f\"Dataset 1 (œÉ={std1:.2f})\", density=True)\n",
        "    plt.hist(data2, bins=20, alpha=0.6, color='green', edgecolor='black', label=f\"Dataset 2 (œÉ={std2:.2f})\", density=True)\n",
        "\n",
        "    # Labels and title\n",
        "    plt.xlabel(\"Values\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.title(\"Comparison of Standard Deviations\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Generate two datasets with different spreads\n",
        "np.random.seed(42)\n",
        "dataset1 = np.random.normal(loc=50, scale=5, size=500)   # Mean=50, Std=5\n",
        "dataset2 = np.random.normal(loc=50, scale=15, size=500)  # Mean=50, Std=15\n",
        "\n",
        "# Compare standard deviations\n",
        "compare_standard_deviations(dataset1, dataset2)\n",
        "Standard Deviation of Dataset 1: 4.91\n",
        "Standard Deviation of Dataset 2: 14.67\n",
        "\n",
        "# 22 Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def calculate_range_iqr(data):\n",
        "    \"\"\"\n",
        "    Computes and visualizes the Range and IQR of a dataset.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): The dataset.\n",
        "\n",
        "    Returns:\n",
        "    None (prints range & IQR and plots boxplot).\n",
        "    \"\"\"\n",
        "    # Compute statistics\n",
        "    data_range = np.max(data) - np.min(data)\n",
        "    q1 = np.percentile(data, 25)\n",
        "    q3 = np.percentile(data, 75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Range: {data_range:.2f}\")\n",
        "    print(f\"IQR: {iqr:.2f} (Q1 = {q1:.2f}, Q3 = {q3:.2f})\")\n",
        "\n",
        "    # Visualization - Boxplot\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.boxplot(data, color=\"skyblue\", width=0.5)\n",
        "    plt.title(\"Boxplot of the Dataset\")\n",
        "    plt.xlabel(\"Values\")\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# Generate normal data\n",
        "np.random.seed(42)\n",
        "normal_data = np.random.normal(loc=50, scale=10, size=500)  # Mean=50, Std=10\n",
        "\n",
        "# Compute Range & IQR\n",
        "calculate_range_iqr(normal_data)\n",
        "Range: 70.94\n",
        "IQR: 13.37 (Q1 = 43.00, Q3 = 56.37)\n",
        "\n",
        "#\n",
        "Before Normalization: Mean = 50.10, Std Dev = 14.72\n",
        "After Normalization: Mean = -0.00, Std Dev = 1.00\n",
        "\n",
        "# 23 Implement Z-score normalization on a dataset and visualize its transformation?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate synthetic dataset\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=15, size=1000)  # Mean=50, Std=15\n",
        "\n",
        "# Z-score normalization\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(data, bins=30, kde=True, color='blue')\n",
        "plt.title('Original Data Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(data_normalized, bins=30, kde=True, color='green')\n",
        "plt.title('Z-score Normalized Data Distribution')\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        " # 24 Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution.?\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def z_score_normalization(data):\n",
        "    \"\"\"\n",
        "    Applies Z-score normalization to a dataset and visualizes the transformation.\n",
        "\n",
        "    Parameters:\n",
        "    data (array-like): The dataset.\n",
        "\n",
        "    Returns:\n",
        "    None (prints summary and plots histograms).\n",
        "    \"\"\"\n",
        "    # Compute mean and standard deviation before normalization\n",
        "    mean_before = np.mean(data)\n",
        "    std_before = np.std(data, ddof=1)\n",
        "\n",
        "    # Apply Z-score normalization\n",
        "    normalized_data = zscore(data)\n",
        "\n",
        "    # Compute mean and standard deviation after normalization\n",
        "    mean_after = np.mean(normalized_data)\n",
        "    std_after = np.std(normalized_data, ddof=1)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Before Normalization: Mean = {mean_before:.2f}, Std Dev = {std_before:.2f}\")\n",
        "    print(f\"After Normalization: Mean = {mean_after:.2f}, Std Dev = {std_after:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Histogram before normalization\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(data, bins=20, kde=True, color=\"blue\", alpha=0.7)\n",
        "    plt.title(\"Original Data Distribution\")\n",
        "    plt.xlabel(\"Original Values\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    # Histogram after normalization\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(normalized_data, bins=20, kde=True, color=\"green\", alpha=0.7)\n",
        "    plt.title(\"Z-Score Normalized Data\")\n",
        "    plt.xlabel(\"Normalized Values\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate sample dataset (Normal Distribution)\n",
        "np.random.seed(42)\n",
        "original_data = np.random.normal(loc=50, scale=15, size=500)  # Mean=50, Std=15\n",
        "\n",
        "# Apply Z-score normalization\n",
        "z_score_normalization(original_data)\n",
        "Before Normalization: Mean = 50.10, Std Dev = 14.72\n",
        "After Normalization: Mean = -0.00, Std Dev = 1.00\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bS23wPmRULQl"
      }
    }
  ]
}